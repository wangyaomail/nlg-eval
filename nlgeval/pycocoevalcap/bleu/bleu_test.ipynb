{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys, math, re\n",
    "from collections import defaultdict\n",
    "\n",
    "def precook(s, n=4, out=False):\n",
    "    words = s.split()\n",
    "    counts = defaultdict(int)\n",
    "    for k in range(1, n + 1):\n",
    "        for i in range(len(words) - k + 1):\n",
    "            ngram = tuple(words[i:i + k])\n",
    "            counts[ngram] += 1\n",
    "    return (len(words), counts)\n",
    "\n",
    "def cook_refs(refs, eff=None, n=4):\n",
    "    reflen = []\n",
    "    maxcounts = {}\n",
    "    for ref in refs:\n",
    "        rl, counts = precook(ref, n)\n",
    "        reflen.append(rl)\n",
    "        for (ngram, count) in counts.items():\n",
    "            maxcounts[ngram] = max(maxcounts.get(ngram, 0), count)\n",
    "    if eff == \"shortest\":\n",
    "        reflen = min(reflen)\n",
    "    elif eff == \"average\":\n",
    "        reflen = float(sum(reflen)) / len(reflen)\n",
    "    return (reflen, maxcounts)\n",
    "\n",
    "def cook_test(test, tup_obj, eff=None, n=4):\n",
    "    (reflen, refmaxcounts) = tup_obj\n",
    "    testlen, counts = precook(test, n, True)\n",
    "    result = {}\n",
    "    if eff == \"closest\":\n",
    "        result[\"reflen\"] = min((abs(l - testlen), l) for l in reflen)[1]\n",
    "    else:\n",
    "        result[\"reflen\"] = reflen\n",
    "    result[\"testlen\"] = testlen\n",
    "    result[\"guess\"] = [max(0, testlen - k + 1) for k in range(1, n + 1)]\n",
    "    result['correct'] = [0] * n\n",
    "    for (ngram, count) in counts.items():\n",
    "        result[\"correct\"][len(ngram) - 1] += min(refmaxcounts.get(ngram, 0), count)\n",
    "    return result\n",
    "\n",
    "class BleuScorer(object):\n",
    "    __slots__ = \"n\", \"crefs\", \"ctest\", \"_score\", \"_ratio\", \"_testlen\", \"_reflen\", \"special_reflen\"\n",
    "    def copy(self):\n",
    "        new = BleuScorer(n=self.n)\n",
    "        new.ctest = copy.copy(self.ctest)\n",
    "        new.crefs = copy.copy(self.crefs)\n",
    "        new._score = None\n",
    "        return new\n",
    "    def __init__(self, test=None, refs=None, n=4, special_reflen=None):\n",
    "        self.n = n\n",
    "        self.crefs = []\n",
    "        self.ctest = []\n",
    "        self.cook_append(test, refs)\n",
    "        self.special_reflen = special_reflen\n",
    "    def cook_append(self, test, refs):\n",
    "        if refs is not None:\n",
    "            self.crefs.append(cook_refs(refs))\n",
    "            if test is not None:\n",
    "                cooked_test = cook_test(test, self.crefs[-1])\n",
    "                self.ctest.append(cooked_test)\n",
    "            else:\n",
    "                self.ctest.append(None)\n",
    "        self._score = None\n",
    "    def ratio(self, option=None):\n",
    "        self.compute_score(option=option)\n",
    "        return self._ratio\n",
    "    def score_ratio(self, option=None):\n",
    "        return (self.fscore(option=option), self.ratio(option=option))\n",
    "    def score_ratio_str(self, option=None):\n",
    "        return \"%.4f (%.2f)\" % self.score_ratio(option)\n",
    "    def reflen(self, option=None):\n",
    "        self.compute_score(option=option)\n",
    "        return self._reflen\n",
    "    def testlen(self, option=None):\n",
    "        self.compute_score(option=option)\n",
    "        return self._testlen\n",
    "    def retest(self, new_test):\n",
    "        if type(new_test) is str:\n",
    "            new_test = [new_test]\n",
    "        assert len(new_test) == len(self.crefs), new_test\n",
    "        self.ctest = []\n",
    "        for t, rs in zip(new_test, self.crefs):\n",
    "            self.ctest.append(cook_test(t, rs))\n",
    "        self._score = None\n",
    "        return self\n",
    "    def rescore(self, new_test):\n",
    "        return self.retest(new_test).compute_score()\n",
    "    def size(self):\n",
    "        assert len(self.crefs) == len(self.ctest), \"refs/test mismatch! %d<>%d\" % (len(self.crefs), len(self.ctest))\n",
    "        return len(self.crefs)\n",
    "    def __iadd__(self, other):\n",
    "        if type(other) is tuple:\n",
    "            self.cook_append(other[0], other[1])\n",
    "        else:\n",
    "            assert self.compatible(other), \"incompatible BLEUs.\"\n",
    "            self.ctest.extend(other.ctest)\n",
    "            self.crefs.extend(other.crefs)\n",
    "            self._score = None\n",
    "\n",
    "        return self\n",
    "    def compatible(self, other):\n",
    "        return isinstance(other, BleuScorer) and self.n == other.n\n",
    "    def single_reflen(self, option=\"average\"):\n",
    "        return self._single_reflen(self.crefs[0][0], option)\n",
    "    def _single_reflen(self, reflens, option=None, testlen=None):\n",
    "        if option == \"shortest\":\n",
    "            reflen = min(reflens)\n",
    "        elif option == \"average\":\n",
    "            reflen = float(sum(reflens)) / len(reflens)\n",
    "        elif option == \"closest\":\n",
    "            reflen = min((abs(l - testlen), l) for l in reflens)[1]\n",
    "        else:\n",
    "            assert False, \"unsupported reflen option %s\" % option\n",
    "        return reflen\n",
    "    def recompute_score(self, option=None, verbose=0):\n",
    "        self._score = None\n",
    "        return self.compute_score(option, verbose)\n",
    "    def compute_score(self, option=None, verbose=0):\n",
    "        n = self.n\n",
    "        small = 1e-9\n",
    "        tiny = 1e-15\n",
    "        bleu_list = [[] for _ in range(n)]\n",
    "        if self._score is not None:\n",
    "            return self._score\n",
    "        if option is None:\n",
    "            option = \"average\" if len(self.crefs) == 1 else \"closest\"\n",
    "        self._testlen = 0\n",
    "        self._reflen = 0\n",
    "        totalcomps = {'testlen': 0, 'reflen': 0, 'guess': [0] * n, 'correct': [0] * n}\n",
    "        for comps in self.ctest:\n",
    "            testlen = comps['testlen']\n",
    "            self._testlen += testlen\n",
    "            if self.special_reflen is None:\n",
    "                reflen = self._single_reflen(comps['reflen'], option, testlen)\n",
    "            else:\n",
    "                reflen = self.special_reflen\n",
    "            self._reflen += reflen\n",
    "            for key in ['guess', 'correct']:\n",
    "                for k in range(n):\n",
    "                    totalcomps[key][k] += comps[key][k]\n",
    "            bleu = 1.\n",
    "            for k in range(n):\n",
    "                bleu *= (float(comps['correct'][k]) + tiny) / (float(comps['guess'][k]) + small)\n",
    "                bleu_list[k].append(bleu ** (1. / (k + 1)))\n",
    "            ratio = (testlen + tiny) / (reflen + small)  ## N.B.: avoid zero division\n",
    "            if ratio < 1:\n",
    "                for k in range(n):\n",
    "                    bleu_list[k][-1] *= math.exp(1 - 1 / ratio)\n",
    "            if verbose > 1:\n",
    "                print(comps, reflen)\n",
    "        totalcomps['reflen'] = self._reflen\n",
    "        totalcomps['testlen'] = self._testlen\n",
    "        bleus = []\n",
    "        bleu = 1.\n",
    "        for k in range(n):\n",
    "            bleu *= float(totalcomps['correct'][k] + tiny) / (totalcomps['guess'][k] + small)\n",
    "            bleus.append(bleu ** (1. / (k + 1)))\n",
    "        ratio = (self._testlen + tiny) / (self._reflen + small)  ## N.B.: avoid zero division\n",
    "        if ratio < 1:\n",
    "            for k in range(n):\n",
    "                bleus[k] *= math.exp(1 - 1 / ratio)\n",
    "        if verbose > 0:\n",
    "            print(totalcomps)\n",
    "            print(\"ratio:\", ratio)\n",
    "        self._score = bleus\n",
    "        return self._score, bleu_list\n",
    "\n",
    "class Bleu:\n",
    "    def __init__(self, n=4):\n",
    "        self._n = n\n",
    "        self._hypo_for_image = {}\n",
    "        self.ref_for_image = {}\n",
    "    def compute_score(self, gts, res):\n",
    "        assert (gts.keys() == res.keys())\n",
    "        imgIds = gts.keys()\n",
    "        bleu_scorer = BleuScorer(n=self._n)\n",
    "        for id in imgIds:\n",
    "            hypo = res[id]\n",
    "            ref = gts[id]\n",
    "            assert (type(hypo) is list)\n",
    "            assert (len(hypo) == 1)\n",
    "            assert (type(ref) is list)\n",
    "            assert (len(ref) >= 1)\n",
    "            bleu_scorer += (hypo[0], ref)\n",
    "        #score, scores = bleu_scorer.compute_score(option='shortest')\n",
    "        score, scores = bleu_scorer.compute_score(option='closest', verbose=1)\n",
    "        #score, scores = bleu_scorer.compute_score(option='average', verbose=1)\n",
    "        # return (bleu, bleu_info)\n",
    "        return score, scores\n",
    "    def method(self):\n",
    "        return \"Bleu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 5, 'reflen': 4, 'guess': [5], 'correct': [4]}\n",
      "ratio: 1.2499999996875002\n",
      "[0.7999999998400001]\n",
      "{'testlen': 5, 'reflen': 4, 'guess': [5, 4], 'correct': [4, 2]}\n",
      "ratio: 1.2499999996875002\n",
      "[0.7999999998400001, 0.6324555318913736]\n",
      "{'testlen': 5, 'reflen': 4, 'guess': [5, 4, 3], 'correct': [4, 2, 1]}\n",
      "ratio: 1.2499999996875002\n",
      "[0.7999999998400001, 0.6324555318913736, 0.5108729547956411]\n",
      "{'testlen': 5, 'reflen': 4, 'guess': [5, 4, 3, 2], 'correct': [4, 2, 1, 0]}\n",
      "ratio: 1.2499999996875002\n",
      "[0.7999999998400001, 0.6324555318913736, 0.5108729547956411, 9.036020033199396e-05]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m      5\u001B[0m     bleu \u001B[38;5;241m=\u001B[39m Bleu(i)\n\u001B[1;32m----> 6\u001B[0m     score, scores \u001B[38;5;241m=\u001B[39m \u001B[43mbleu\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrefs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(score)\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mBleu.compute_score\u001B[1;34m(self, gts, res)\u001B[0m\n\u001B[0;32m    187\u001B[0m     bleu_scorer \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (hypo[\u001B[38;5;241m0\u001B[39m], ref)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;66;03m#score, scores = bleu_scorer.compute_score(option='shortest')\u001B[39;00m\n\u001B[1;32m--> 189\u001B[0m score, scores \u001B[38;5;241m=\u001B[39m \u001B[43mbleu_scorer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43moption\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclosest\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m#score, scores = bleu_scorer.compute_score(option='average', verbose=1)\u001B[39;00m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;66;03m# return (bleu, bleu_info)\u001B[39;00m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m score, scores\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mBleuScorer.compute_score\u001B[1;34m(self, option, verbose)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mguess\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcorrect\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n):\n\u001B[1;32m--> 143\u001B[0m         totalcomps[key][k] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mcomps\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    144\u001B[0m bleu \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n):\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "refs = {0: [\"this is a test\", \"this is also a test\"]}\n",
    "hyps = {0: [\"this is a good test\"]}\n",
    "\n",
    "for i in range(1,10):\n",
    "    bleu = Bleu(i)\n",
    "    score, scores = bleu.compute_score(refs, hyps)\n",
    "    print(score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
